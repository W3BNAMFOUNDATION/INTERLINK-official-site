<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>INTERLINK™ — Install</title>
    <link rel="stylesheet" href="assets/styles/style.css">
</head>

<body>

<header class="navbar">
    <img src="assets/logo/logo.png" class="nav-logo" />
    <nav>
        <a href="index.html">Overview</a>
        <a href="features.html">Features</a>
        <a href="install.html" class="active">Install</a>
        <a href="docs.html">Docs</a>
        <a href="pricing.html">Pricing</a>
        <a href="compare.html">Compare</a>
        <a href="demo.html">Demo</a>
        <a href="invest.html">Invest</a>
        <a href="contact.html">Contact</a>
    </nav>
</header>

<section class="hero">
    <h1>Install INTERLINK™</h1>
    <p>Follow these instructions to install and run the unified AI workspace locally.</p>
</section>

<section class="container">

    <h2>1. Requirements</h2>
    <ul>
        <li>Python 3.10+</li>
        <li>Node.js 18+ (if using frontend panel)</li>
        <li>Ollama / DeepSeek / Groq (optional depending on profiles)</li>
        <li>Windows, macOS, or Linux</li>
    </ul>

    <h2>2. One-Shot Installer</h2>
    <p>Run the installer script generated by Codex:</p>

<pre><code>
python install.py
</code></pre>

    <p>The installer performs:</p>
    <ul>
        <li>Virtual environment setup</li>
        <li>Backend dependency installation</li>
        <li>Frontend dependency installation</li>
        <li>Service profile setup</li>
        <li>Test boot (backend + panel)</li>
    </ul>

    <h2>3. Manual Install (Optional)</h2>

    <h3>Step 1 — Create venv</h3>
<pre><code>
python -m venv venv
source venv/bin/activate     # Linux/macOS
venv\Scripts\activate        # Windows
</code></pre>

    <h3>Step 2 — Install requirements</h3>
<pre><code>
pip install -r requirements.txt
</code></pre>

    <h3>Step 3 — Configure service profiles</h3>

<pre><code>
config/service_profiles.yaml
</code></pre>

    <p>Example:</p>

<pre><code>
services:
  ollama:
    type: ollama
    base_url: http://localhost:11434
    model: llama3.2

  deepseek:
    type: openai_compat
    base_url: https://api.deepseek.com/v1
    env_key: DEEPSEEK_API_KEY
    model: deepseek-chat

  groq:
    type: openai_compat
    base_url: https://api.groq.com/openai/v1
    env_key: GROQ_API_KEY
    model: llama-3.1-70b-versatile
</code></pre>

    <h2>4. Run INTERLINK™</h2>
<pre><code>
python backend/main.py
</code></pre>

    <p>Frontend (optional):</p>

<pre><code>
cd frontend
npm install
npm run dev
</code></pre>

    <h2>5. Updating</h2>
    <p>Use Git to pull new updates:</p>

<pre><code>
git pull origin main
</code></pre>

    <h2>6. Uninstall</h2>

<pre><code>
rm -rf venv
rm -rf backend/__pycache__
rm -rf frontend/node_modules
</code></pre>

</section>

<footer class="footer">
    <p>INTERLINK™ — Unified AI Workspace</p>
</footer>

<script src="assets/scripts/script.js"></script>
</body>
</html>
